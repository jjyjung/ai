{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_keras_CNN_CIFAR10_CV.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOwa9qcE6CmahvpRdlTJtZ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjyjung/ai/blob/gh-pages/tf_keras_CNN_CIFAR10_CV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W1W6vyWN4vIM",
        "outputId": "da9613a1-5a03-48e6-c8be-ea203bc6f555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc_000\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.5779 - accuracy: 0.4241 - val_loss: 1.2960 - val_accuracy: 0.5279 - 4s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.1720 - accuracy: 0.5796 - val_loss: 1.1322 - val_accuracy: 0.6004 - 3s/epoch - 10ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 0.9805 - accuracy: 0.6523 - val_loss: 0.9871 - val_accuracy: 0.6488 - 3s/epoch - 9ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 0.8198 - accuracy: 0.7128 - val_loss: 0.9464 - val_accuracy: 0.6712 - 3s/epoch - 10ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 0.7042 - accuracy: 0.7540 - val_loss: 0.8482 - val_accuracy: 0.7100 - 3s/epoch - 10ms/step\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.5843 - accuracy: 0.4218 - val_loss: 1.2946 - val_accuracy: 0.5271 - 4s/epoch - 12ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.1624 - accuracy: 0.5864 - val_loss: 1.2288 - val_accuracy: 0.5692 - 3s/epoch - 10ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 0.9699 - accuracy: 0.6612 - val_loss: 0.9954 - val_accuracy: 0.6574 - 3s/epoch - 9ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 0.8351 - accuracy: 0.7094 - val_loss: 0.8874 - val_accuracy: 0.6967 - 3s/epoch - 9ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 0.7157 - accuracy: 0.7505 - val_loss: 0.8338 - val_accuracy: 0.7148 - 3s/epoch - 9ms/step\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.6009 - accuracy: 0.4175 - val_loss: 1.3340 - val_accuracy: 0.5154 - 4s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.2042 - accuracy: 0.5742 - val_loss: 1.0897 - val_accuracy: 0.6087 - 3s/epoch - 10ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 1.0197 - accuracy: 0.6409 - val_loss: 1.0078 - val_accuracy: 0.6473 - 3s/epoch - 10ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 0.8889 - accuracy: 0.6908 - val_loss: 0.8965 - val_accuracy: 0.6827 - 3s/epoch - 10ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 0.7664 - accuracy: 0.7314 - val_loss: 0.8711 - val_accuracy: 0.6967 - 3s/epoch - 9ms/step\n",
            "Epoch 1/5\n",
            "313/313 - 45s - loss: 1.5756 - accuracy: 0.4236 - val_loss: 1.2823 - val_accuracy: 0.5390 - 45s/epoch - 144ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.1910 - accuracy: 0.5757 - val_loss: 1.0993 - val_accuracy: 0.6102 - 3s/epoch - 9ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 0.9920 - accuracy: 0.6522 - val_loss: 0.9720 - val_accuracy: 0.6596 - 3s/epoch - 9ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 0.8552 - accuracy: 0.7025 - val_loss: 0.8806 - val_accuracy: 0.6910 - 3s/epoch - 10ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 0.7465 - accuracy: 0.7388 - val_loss: 0.8762 - val_accuracy: 0.6966 - 3s/epoch - 10ms/step\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.5772 - accuracy: 0.4251 - val_loss: 1.3641 - val_accuracy: 0.5013 - 4s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.1727 - accuracy: 0.5817 - val_loss: 1.0787 - val_accuracy: 0.6183 - 3s/epoch - 9ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 0.9918 - accuracy: 0.6514 - val_loss: 0.9780 - val_accuracy: 0.6522 - 3s/epoch - 10ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 0.8438 - accuracy: 0.7091 - val_loss: 0.8769 - val_accuracy: 0.6949 - 3s/epoch - 9ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 0.7426 - accuracy: 0.7415 - val_loss: 0.8521 - val_accuracy: 0.7050 - 3s/epoch - 9ms/step\n",
            "acc_001\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.6980 - accuracy: 0.3990 - val_loss: 1.3884 - val_accuracy: 0.5136 - 4s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.2846 - accuracy: 0.5574 - val_loss: 1.2757 - val_accuracy: 0.5592 - 3s/epoch - 9ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 1.0876 - accuracy: 0.6298 - val_loss: 1.0192 - val_accuracy: 0.6559 - 3s/epoch - 9ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 0.9453 - accuracy: 0.6819 - val_loss: 0.9835 - val_accuracy: 0.6720 - 3s/epoch - 9ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 0.8427 - accuracy: 0.7197 - val_loss: 0.8920 - val_accuracy: 0.7013 - 3s/epoch - 9ms/step\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.6710 - accuracy: 0.4103 - val_loss: 1.3893 - val_accuracy: 0.5124 - 4s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.2561 - accuracy: 0.5658 - val_loss: 1.1474 - val_accuracy: 0.6006 - 3s/epoch - 10ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 1.0769 - accuracy: 0.6303 - val_loss: 1.0362 - val_accuracy: 0.6468 - 3s/epoch - 10ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 0.9484 - accuracy: 0.6800 - val_loss: 0.9901 - val_accuracy: 0.6614 - 3s/epoch - 10ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 0.8529 - accuracy: 0.7157 - val_loss: 0.9144 - val_accuracy: 0.6953 - 3s/epoch - 9ms/step\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.6722 - accuracy: 0.4155 - val_loss: 1.4443 - val_accuracy: 0.4844 - 4s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.2926 - accuracy: 0.5517 - val_loss: 1.1808 - val_accuracy: 0.5905 - 3s/epoch - 10ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 1.1151 - accuracy: 0.6198 - val_loss: 1.0803 - val_accuracy: 0.6323 - 3s/epoch - 10ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 0.9836 - accuracy: 0.6673 - val_loss: 1.0205 - val_accuracy: 0.6497 - 3s/epoch - 10ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 0.8799 - accuracy: 0.7071 - val_loss: 0.9778 - val_accuracy: 0.6697 - 3s/epoch - 10ms/step\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.6241 - accuracy: 0.4327 - val_loss: 1.3404 - val_accuracy: 0.5334 - 4s/epoch - 12ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.2310 - accuracy: 0.5744 - val_loss: 1.1695 - val_accuracy: 0.5977 - 3s/epoch - 9ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 1.0529 - accuracy: 0.6398 - val_loss: 1.0335 - val_accuracy: 0.6413 - 3s/epoch - 9ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 0.9358 - accuracy: 0.6830 - val_loss: 1.0045 - val_accuracy: 0.6542 - 3s/epoch - 9ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 0.8384 - accuracy: 0.7186 - val_loss: 0.9275 - val_accuracy: 0.6939 - 3s/epoch - 9ms/step\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.6544 - accuracy: 0.4209 - val_loss: 1.3799 - val_accuracy: 0.5167 - 4s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.2663 - accuracy: 0.5610 - val_loss: 1.1544 - val_accuracy: 0.6057 - 3s/epoch - 10ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 1.0889 - accuracy: 0.6326 - val_loss: 1.0787 - val_accuracy: 0.6297 - 3s/epoch - 10ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 0.9583 - accuracy: 0.6777 - val_loss: 0.9850 - val_accuracy: 0.6716 - 3s/epoch - 10ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 0.8507 - accuracy: 0.7153 - val_loss: 0.9130 - val_accuracy: 0.6943 - 3s/epoch - 10ms/step\n",
            "acc_010\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.7158 - accuracy: 0.3672 - val_loss: 1.3604 - val_accuracy: 0.5047 - 4s/epoch - 14ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.3467 - accuracy: 0.5157 - val_loss: 1.1465 - val_accuracy: 0.5907 - 3s/epoch - 10ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 1.1612 - accuracy: 0.5866 - val_loss: 1.0079 - val_accuracy: 0.6395 - 3s/epoch - 11ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 1.0401 - accuracy: 0.6298 - val_loss: 0.9254 - val_accuracy: 0.6767 - 3s/epoch - 11ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 0.9537 - accuracy: 0.6645 - val_loss: 0.8695 - val_accuracy: 0.6971 - 3s/epoch - 10ms/step\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.7016 - accuracy: 0.3679 - val_loss: 1.3527 - val_accuracy: 0.4984 - 4s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.3444 - accuracy: 0.5135 - val_loss: 1.2198 - val_accuracy: 0.5619 - 3s/epoch - 10ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 1.1922 - accuracy: 0.5745 - val_loss: 1.0429 - val_accuracy: 0.6291 - 3s/epoch - 11ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 1.0696 - accuracy: 0.6202 - val_loss: 1.0001 - val_accuracy: 0.6429 - 3s/epoch - 11ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 0.9877 - accuracy: 0.6496 - val_loss: 0.9400 - val_accuracy: 0.6665 - 3s/epoch - 10ms/step\n",
            "Epoch 1/5\n",
            "313/313 - 5s - loss: 1.7273 - accuracy: 0.3589 - val_loss: 1.3974 - val_accuracy: 0.4921 - 5s/epoch - 15ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.3599 - accuracy: 0.5090 - val_loss: 1.2129 - val_accuracy: 0.5656 - 3s/epoch - 11ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 1.1942 - accuracy: 0.5749 - val_loss: 1.0691 - val_accuracy: 0.6260 - 3s/epoch - 10ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 1.0649 - accuracy: 0.6234 - val_loss: 0.9524 - val_accuracy: 0.6686 - 3s/epoch - 10ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 0.9731 - accuracy: 0.6590 - val_loss: 0.9058 - val_accuracy: 0.6856 - 3s/epoch - 10ms/step\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.6979 - accuracy: 0.3705 - val_loss: 1.3389 - val_accuracy: 0.5112 - 4s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.2828 - accuracy: 0.5392 - val_loss: 1.1480 - val_accuracy: 0.5946 - 3s/epoch - 10ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 1.1156 - accuracy: 0.6040 - val_loss: 1.0438 - val_accuracy: 0.6264 - 3s/epoch - 10ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 0.9977 - accuracy: 0.6471 - val_loss: 0.9273 - val_accuracy: 0.6738 - 3s/epoch - 10ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 0.9119 - accuracy: 0.6787 - val_loss: 0.8407 - val_accuracy: 0.7117 - 3s/epoch - 11ms/step\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.7326 - accuracy: 0.3587 - val_loss: 1.3965 - val_accuracy: 0.4991 - 4s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.3229 - accuracy: 0.5250 - val_loss: 1.1696 - val_accuracy: 0.5794 - 3s/epoch - 10ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 1.1293 - accuracy: 0.6007 - val_loss: 0.9956 - val_accuracy: 0.6495 - 3s/epoch - 10ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 1.0107 - accuracy: 0.6443 - val_loss: 0.8989 - val_accuracy: 0.6860 - 3s/epoch - 10ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 0.9271 - accuracy: 0.6722 - val_loss: 0.8571 - val_accuracy: 0.6953 - 3s/epoch - 10ms/step\n",
            "acc_011\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.7885 - accuracy: 0.3615 - val_loss: 1.4854 - val_accuracy: 0.4807 - 4s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.3814 - accuracy: 0.5138 - val_loss: 1.2092 - val_accuracy: 0.5834 - 3s/epoch - 10ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 1.2333 - accuracy: 0.5713 - val_loss: 1.0940 - val_accuracy: 0.6292 - 3s/epoch - 10ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 1.1008 - accuracy: 0.6229 - val_loss: 0.9531 - val_accuracy: 0.6784 - 3s/epoch - 10ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 1.0065 - accuracy: 0.6545 - val_loss: 0.9102 - val_accuracy: 0.6899 - 3s/epoch - 10ms/step\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.7875 - accuracy: 0.3625 - val_loss: 1.4510 - val_accuracy: 0.4905 - 4s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.3964 - accuracy: 0.5105 - val_loss: 1.2694 - val_accuracy: 0.5590 - 3s/epoch - 10ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 1.2330 - accuracy: 0.5729 - val_loss: 1.0917 - val_accuracy: 0.6215 - 3s/epoch - 10ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 1.1148 - accuracy: 0.6162 - val_loss: 1.0418 - val_accuracy: 0.6453 - 3s/epoch - 10ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 1.0405 - accuracy: 0.6428 - val_loss: 0.9619 - val_accuracy: 0.6747 - 3s/epoch - 11ms/step\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.8231 - accuracy: 0.3416 - val_loss: 1.4358 - val_accuracy: 0.4850 - 4s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.4198 - accuracy: 0.4985 - val_loss: 1.2687 - val_accuracy: 0.5527 - 3s/epoch - 10ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 1.2650 - accuracy: 0.5574 - val_loss: 1.1830 - val_accuracy: 0.5943 - 3s/epoch - 10ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 1.1601 - accuracy: 0.5985 - val_loss: 1.1031 - val_accuracy: 0.6255 - 3s/epoch - 11ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 1.0784 - accuracy: 0.6293 - val_loss: 0.9943 - val_accuracy: 0.6581 - 3s/epoch - 11ms/step\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.7787 - accuracy: 0.3672 - val_loss: 1.5081 - val_accuracy: 0.4575 - 4s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.3955 - accuracy: 0.5099 - val_loss: 1.2739 - val_accuracy: 0.5575 - 3s/epoch - 10ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 1.2476 - accuracy: 0.5643 - val_loss: 1.1643 - val_accuracy: 0.5907 - 3s/epoch - 11ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 1.1297 - accuracy: 0.6114 - val_loss: 1.0318 - val_accuracy: 0.6441 - 3s/epoch - 10ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 1.0376 - accuracy: 0.6460 - val_loss: 0.9737 - val_accuracy: 0.6666 - 3s/epoch - 10ms/step\n",
            "Epoch 1/5\n",
            "313/313 - 4s - loss: 1.8496 - accuracy: 0.3354 - val_loss: 1.4837 - val_accuracy: 0.4750 - 4s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "313/313 - 3s - loss: 1.4304 - accuracy: 0.4923 - val_loss: 1.2567 - val_accuracy: 0.5553 - 3s/epoch - 11ms/step\n",
            "Epoch 3/5\n",
            "313/313 - 3s - loss: 1.2462 - accuracy: 0.5626 - val_loss: 1.0943 - val_accuracy: 0.6240 - 3s/epoch - 10ms/step\n",
            "Epoch 4/5\n",
            "313/313 - 3s - loss: 1.1278 - accuracy: 0.6118 - val_loss: 0.9952 - val_accuracy: 0.6541 - 3s/epoch - 10ms/step\n",
            "Epoch 5/5\n",
            "313/313 - 3s - loss: 1.0339 - accuracy: 0.6454 - val_loss: 0.9773 - val_accuracy: 0.6653 - 3s/epoch - 11ms/step\n",
            "acc_100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "391/391 - 21s - loss: 1.6038 - accuracy: 0.4143 - val_loss: 1.3008 - val_accuracy: 0.5374 - 21s/epoch - 54ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 20s - loss: 1.2372 - accuracy: 0.5571 - val_loss: 1.1294 - val_accuracy: 0.5987 - 20s/epoch - 52ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 20s - loss: 1.0746 - accuracy: 0.6200 - val_loss: 0.9801 - val_accuracy: 0.6524 - 20s/epoch - 52ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 20s - loss: 0.9717 - accuracy: 0.6586 - val_loss: 0.9305 - val_accuracy: 0.6742 - 20s/epoch - 51ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 21s - loss: 0.9029 - accuracy: 0.6830 - val_loss: 0.8625 - val_accuracy: 0.7017 - 21s/epoch - 53ms/step\n",
            "Epoch 1/5\n",
            "391/391 - 21s - loss: 1.6394 - accuracy: 0.3997 - val_loss: 1.2959 - val_accuracy: 0.5360 - 21s/epoch - 54ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 20s - loss: 1.2761 - accuracy: 0.5424 - val_loss: 1.1290 - val_accuracy: 0.6009 - 20s/epoch - 52ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 21s - loss: 1.0996 - accuracy: 0.6126 - val_loss: 0.9820 - val_accuracy: 0.6550 - 21s/epoch - 53ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 20s - loss: 0.9967 - accuracy: 0.6498 - val_loss: 0.8657 - val_accuracy: 0.6980 - 20s/epoch - 51ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 20s - loss: 0.9102 - accuracy: 0.6794 - val_loss: 0.9113 - val_accuracy: 0.6902 - 20s/epoch - 52ms/step\n",
            "Epoch 1/5\n",
            "391/391 - 21s - loss: 1.6016 - accuracy: 0.4151 - val_loss: 1.3057 - val_accuracy: 0.5346 - 21s/epoch - 54ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 21s - loss: 1.2556 - accuracy: 0.5518 - val_loss: 1.0736 - val_accuracy: 0.6199 - 21s/epoch - 53ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 20s - loss: 1.0992 - accuracy: 0.6121 - val_loss: 1.1227 - val_accuracy: 0.6095 - 20s/epoch - 52ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 20s - loss: 0.9926 - accuracy: 0.6475 - val_loss: 0.8835 - val_accuracy: 0.6916 - 20s/epoch - 51ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 20s - loss: 0.9079 - accuracy: 0.6813 - val_loss: 0.8554 - val_accuracy: 0.7029 - 20s/epoch - 52ms/step\n",
            "Epoch 1/5\n",
            "391/391 - 21s - loss: 1.6147 - accuracy: 0.4059 - val_loss: 1.2538 - val_accuracy: 0.5453 - 21s/epoch - 54ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 20s - loss: 1.2581 - accuracy: 0.5463 - val_loss: 1.0942 - val_accuracy: 0.6150 - 20s/epoch - 51ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 21s - loss: 1.0710 - accuracy: 0.6188 - val_loss: 0.9854 - val_accuracy: 0.6563 - 21s/epoch - 53ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 21s - loss: 0.9532 - accuracy: 0.6662 - val_loss: 0.9620 - val_accuracy: 0.6704 - 21s/epoch - 53ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 20s - loss: 0.8836 - accuracy: 0.6906 - val_loss: 0.8005 - val_accuracy: 0.7261 - 20s/epoch - 52ms/step\n",
            "Epoch 1/5\n",
            "391/391 - 21s - loss: 1.6319 - accuracy: 0.4033 - val_loss: 1.3148 - val_accuracy: 0.5214 - 21s/epoch - 55ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 20s - loss: 1.3107 - accuracy: 0.5265 - val_loss: 1.2287 - val_accuracy: 0.5683 - 20s/epoch - 52ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 20s - loss: 1.1365 - accuracy: 0.5977 - val_loss: 1.0774 - val_accuracy: 0.6201 - 20s/epoch - 52ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 20s - loss: 1.0277 - accuracy: 0.6397 - val_loss: 0.9663 - val_accuracy: 0.6670 - 20s/epoch - 51ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 21s - loss: 0.9442 - accuracy: 0.6669 - val_loss: 0.8824 - val_accuracy: 0.6935 - 21s/epoch - 53ms/step\n",
            "acc_101\n",
            "Epoch 1/5\n",
            "391/391 - 21s - loss: 1.7013 - accuracy: 0.3941 - val_loss: 1.3807 - val_accuracy: 0.5157 - 21s/epoch - 54ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 20s - loss: 1.3474 - accuracy: 0.5249 - val_loss: 1.2132 - val_accuracy: 0.5738 - 20s/epoch - 52ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 20s - loss: 1.1913 - accuracy: 0.5886 - val_loss: 1.0772 - val_accuracy: 0.6352 - 20s/epoch - 52ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 20s - loss: 1.0872 - accuracy: 0.6253 - val_loss: 0.9864 - val_accuracy: 0.6598 - 20s/epoch - 51ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 20s - loss: 1.0030 - accuracy: 0.6579 - val_loss: 0.9683 - val_accuracy: 0.6738 - 20s/epoch - 52ms/step\n",
            "Epoch 1/5\n",
            "391/391 - 21s - loss: 1.7026 - accuracy: 0.3956 - val_loss: 1.3639 - val_accuracy: 0.5230 - 21s/epoch - 54ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 20s - loss: 1.3376 - accuracy: 0.5314 - val_loss: 1.1846 - val_accuracy: 0.5954 - 20s/epoch - 52ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 20s - loss: 1.1674 - accuracy: 0.5967 - val_loss: 1.0289 - val_accuracy: 0.6499 - 20s/epoch - 51ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 20s - loss: 1.0555 - accuracy: 0.6387 - val_loss: 0.9640 - val_accuracy: 0.6702 - 20s/epoch - 52ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 20s - loss: 0.9745 - accuracy: 0.6656 - val_loss: 0.9776 - val_accuracy: 0.6698 - 20s/epoch - 52ms/step\n",
            "Epoch 1/5\n",
            "391/391 - 21s - loss: 1.7076 - accuracy: 0.3961 - val_loss: 1.4320 - val_accuracy: 0.4936 - 21s/epoch - 53ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 20s - loss: 1.3572 - accuracy: 0.5235 - val_loss: 1.1924 - val_accuracy: 0.5920 - 20s/epoch - 51ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 20s - loss: 1.1875 - accuracy: 0.5902 - val_loss: 1.0488 - val_accuracy: 0.6372 - 20s/epoch - 52ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 20s - loss: 1.0760 - accuracy: 0.6282 - val_loss: 1.0198 - val_accuracy: 0.6571 - 20s/epoch - 52ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 20s - loss: 0.9963 - accuracy: 0.6603 - val_loss: 0.9457 - val_accuracy: 0.6783 - 20s/epoch - 52ms/step\n",
            "Epoch 1/5\n",
            "391/391 - 21s - loss: 1.7058 - accuracy: 0.3901 - val_loss: 1.3597 - val_accuracy: 0.5216 - 21s/epoch - 54ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 20s - loss: 1.3636 - accuracy: 0.5199 - val_loss: 1.1990 - val_accuracy: 0.5813 - 20s/epoch - 51ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 20s - loss: 1.2037 - accuracy: 0.5813 - val_loss: 1.1264 - val_accuracy: 0.6155 - 20s/epoch - 51ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 20s - loss: 1.1063 - accuracy: 0.6180 - val_loss: 0.9841 - val_accuracy: 0.6622 - 20s/epoch - 52ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 21s - loss: 1.0324 - accuracy: 0.6460 - val_loss: 1.0105 - val_accuracy: 0.6563 - 21s/epoch - 53ms/step\n",
            "Epoch 1/5\n",
            "391/391 - 22s - loss: 1.6592 - accuracy: 0.4142 - val_loss: 1.3518 - val_accuracy: 0.5272 - 22s/epoch - 55ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 21s - loss: 1.3151 - accuracy: 0.5410 - val_loss: 1.1784 - val_accuracy: 0.5846 - 21s/epoch - 54ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 21s - loss: 1.1693 - accuracy: 0.5963 - val_loss: 1.0238 - val_accuracy: 0.6494 - 21s/epoch - 52ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 21s - loss: 1.0601 - accuracy: 0.6369 - val_loss: 0.9769 - val_accuracy: 0.6650 - 21s/epoch - 53ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 21s - loss: 0.9689 - accuracy: 0.6691 - val_loss: 0.9457 - val_accuracy: 0.6836 - 21s/epoch - 53ms/step\n",
            "acc_110\n",
            "Epoch 1/5\n",
            "391/391 - 22s - loss: 1.7289 - accuracy: 0.3600 - val_loss: 1.3190 - val_accuracy: 0.5182 - 22s/epoch - 55ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 21s - loss: 1.3779 - accuracy: 0.4988 - val_loss: 1.1983 - val_accuracy: 0.5652 - 21s/epoch - 54ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 21s - loss: 1.2328 - accuracy: 0.5565 - val_loss: 1.0369 - val_accuracy: 0.6301 - 21s/epoch - 53ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 20s - loss: 1.1392 - accuracy: 0.5950 - val_loss: 0.9672 - val_accuracy: 0.6578 - 20s/epoch - 52ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 21s - loss: 1.0628 - accuracy: 0.6197 - val_loss: 0.9814 - val_accuracy: 0.6521 - 21s/epoch - 53ms/step\n",
            "Epoch 1/5\n",
            "391/391 - 21s - loss: 1.7091 - accuracy: 0.3681 - val_loss: 1.3721 - val_accuracy: 0.5026 - 21s/epoch - 55ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 21s - loss: 1.3720 - accuracy: 0.5022 - val_loss: 1.1692 - val_accuracy: 0.5777 - 21s/epoch - 54ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 21s - loss: 1.2253 - accuracy: 0.5641 - val_loss: 1.0987 - val_accuracy: 0.6068 - 21s/epoch - 54ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 21s - loss: 1.1235 - accuracy: 0.5991 - val_loss: 0.9308 - val_accuracy: 0.6717 - 21s/epoch - 54ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 21s - loss: 1.0572 - accuracy: 0.6258 - val_loss: 0.8773 - val_accuracy: 0.6911 - 21s/epoch - 54ms/step\n",
            "Epoch 1/5\n",
            "391/391 - 22s - loss: 1.7411 - accuracy: 0.3551 - val_loss: 1.4051 - val_accuracy: 0.4929 - 22s/epoch - 56ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 21s - loss: 1.4050 - accuracy: 0.4914 - val_loss: 1.2275 - val_accuracy: 0.5577 - 21s/epoch - 53ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 21s - loss: 1.2548 - accuracy: 0.5478 - val_loss: 1.1907 - val_accuracy: 0.5749 - 21s/epoch - 54ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 21s - loss: 1.1525 - accuracy: 0.5882 - val_loss: 1.0300 - val_accuracy: 0.6403 - 21s/epoch - 54ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 21s - loss: 1.0869 - accuracy: 0.6135 - val_loss: 0.9030 - val_accuracy: 0.6801 - 21s/epoch - 53ms/step\n",
            "Epoch 1/5\n",
            "391/391 - 22s - loss: 1.7172 - accuracy: 0.3621 - val_loss: 1.3534 - val_accuracy: 0.5018 - 22s/epoch - 56ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 22s - loss: 1.3689 - accuracy: 0.5049 - val_loss: 1.2536 - val_accuracy: 0.5552 - 22s/epoch - 55ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 22s - loss: 1.2123 - accuracy: 0.5656 - val_loss: 1.0596 - val_accuracy: 0.6271 - 22s/epoch - 55ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 21s - loss: 1.0962 - accuracy: 0.6122 - val_loss: 0.9560 - val_accuracy: 0.6620 - 21s/epoch - 54ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 21s - loss: 1.0270 - accuracy: 0.6367 - val_loss: 0.9058 - val_accuracy: 0.6839 - 21s/epoch - 54ms/step\n",
            "Epoch 1/5\n",
            "391/391 - 23s - loss: 1.7293 - accuracy: 0.3587 - val_loss: 1.3125 - val_accuracy: 0.5208 - 23s/epoch - 58ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 21s - loss: 1.3731 - accuracy: 0.5032 - val_loss: 1.1611 - val_accuracy: 0.5868 - 21s/epoch - 54ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 21s - loss: 1.2196 - accuracy: 0.5615 - val_loss: 1.0343 - val_accuracy: 0.6381 - 21s/epoch - 55ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 21s - loss: 1.1105 - accuracy: 0.6058 - val_loss: 0.9528 - val_accuracy: 0.6575 - 21s/epoch - 54ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 22s - loss: 1.0366 - accuracy: 0.6332 - val_loss: 0.9353 - val_accuracy: 0.6762 - 22s/epoch - 55ms/step\n",
            "acc_111\n",
            "Epoch 1/5\n",
            "391/391 - 23s - loss: 1.8028 - accuracy: 0.3470 - val_loss: 1.4947 - val_accuracy: 0.4736 - 23s/epoch - 58ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 21s - loss: 1.4565 - accuracy: 0.4789 - val_loss: 1.2947 - val_accuracy: 0.5434 - 21s/epoch - 55ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 22s - loss: 1.3176 - accuracy: 0.5351 - val_loss: 1.1595 - val_accuracy: 0.5957 - 22s/epoch - 55ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 21s - loss: 1.2343 - accuracy: 0.5682 - val_loss: 1.1367 - val_accuracy: 0.6020 - 21s/epoch - 54ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 21s - loss: 1.1660 - accuracy: 0.5971 - val_loss: 1.0294 - val_accuracy: 0.6460 - 21s/epoch - 55ms/step\n",
            "Epoch 1/5\n",
            "391/391 - 22s - loss: 1.8538 - accuracy: 0.3310 - val_loss: 1.5410 - val_accuracy: 0.4492 - 22s/epoch - 56ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 21s - loss: 1.5041 - accuracy: 0.4587 - val_loss: 1.3324 - val_accuracy: 0.5214 - 21s/epoch - 54ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 21s - loss: 1.3611 - accuracy: 0.5179 - val_loss: 1.1752 - val_accuracy: 0.5855 - 21s/epoch - 55ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 21s - loss: 1.2561 - accuracy: 0.5597 - val_loss: 1.0543 - val_accuracy: 0.6347 - 21s/epoch - 54ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 21s - loss: 1.1820 - accuracy: 0.5885 - val_loss: 1.0103 - val_accuracy: 0.6451 - 21s/epoch - 55ms/step\n",
            "Epoch 1/5\n",
            "391/391 - 22s - loss: 1.8223 - accuracy: 0.3396 - val_loss: 1.4353 - val_accuracy: 0.4842 - 22s/epoch - 56ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 21s - loss: 1.4604 - accuracy: 0.4784 - val_loss: 1.2462 - val_accuracy: 0.5588 - 21s/epoch - 55ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 21s - loss: 1.3198 - accuracy: 0.5370 - val_loss: 1.1821 - val_accuracy: 0.5863 - 21s/epoch - 55ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 21s - loss: 1.2385 - accuracy: 0.5680 - val_loss: 1.0590 - val_accuracy: 0.6312 - 21s/epoch - 53ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 21s - loss: 1.1761 - accuracy: 0.5919 - val_loss: 1.0137 - val_accuracy: 0.6547 - 21s/epoch - 54ms/step\n",
            "Epoch 1/5\n",
            "391/391 - 22s - loss: 1.7956 - accuracy: 0.3557 - val_loss: 1.4008 - val_accuracy: 0.4967 - 22s/epoch - 56ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 21s - loss: 1.4612 - accuracy: 0.4794 - val_loss: 1.3045 - val_accuracy: 0.5396 - 21s/epoch - 53ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 21s - loss: 1.3354 - accuracy: 0.5290 - val_loss: 1.2128 - val_accuracy: 0.5794 - 21s/epoch - 54ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 21s - loss: 1.2439 - accuracy: 0.5660 - val_loss: 1.1200 - val_accuracy: 0.6174 - 21s/epoch - 54ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 21s - loss: 1.1735 - accuracy: 0.5921 - val_loss: 1.0460 - val_accuracy: 0.6428 - 21s/epoch - 53ms/step\n",
            "Epoch 1/5\n",
            "391/391 - 22s - loss: 1.8092 - accuracy: 0.3496 - val_loss: 1.4705 - val_accuracy: 0.4782 - 22s/epoch - 55ms/step\n",
            "Epoch 2/5\n",
            "391/391 - 20s - loss: 1.4539 - accuracy: 0.4803 - val_loss: 1.2872 - val_accuracy: 0.5378 - 20s/epoch - 52ms/step\n",
            "Epoch 3/5\n",
            "391/391 - 21s - loss: 1.3246 - accuracy: 0.5320 - val_loss: 1.2588 - val_accuracy: 0.5653 - 21s/epoch - 54ms/step\n",
            "Epoch 4/5\n",
            "391/391 - 21s - loss: 1.2273 - accuracy: 0.5715 - val_loss: 1.1057 - val_accuracy: 0.6206 - 21s/epoch - 53ms/step\n",
            "Epoch 5/5\n",
            "391/391 - 21s - loss: 1.1599 - accuracy: 0.6001 - val_loss: 1.0611 - val_accuracy: 0.6370 - 21s/epoch - 53ms/step\n",
            "출력 형식: [Data augmentation-Dropout-l2 regularizer] (교차검증 시도/평균)\n",
            "[000] ( [0.7031000256538391, 0.7135999798774719, 0.7059000134468079, 0.6945000290870667, 0.7085999846458435] / 0.7051400065422058 )\n",
            "[001] ( [0.70660001039505, 0.696399986743927, 0.6730999946594238, 0.6870999932289124, 0.6988999843597412] / 0.6924199938774109 )\n",
            "[010] ( [0.6955999732017517, 0.6710000038146973, 0.6891000270843506, 0.697700023651123, 0.7027000188827515] / 0.6912200093269348 )\n",
            "[011] ( [0.6909000277519226, 0.6739000082015991, 0.6662999987602234, 0.666100025177002, 0.6639000177383423] / 0.6722200155258179 )\n",
            "[100] ( [0.7264999747276306, 0.6990000009536743, 0.7294999957084656, 0.7400000095367432, 0.7146999835968018] / 0.721939992904663 )\n",
            "[101] ( [0.685699999332428, 0.6851000189781189, 0.6992999911308289, 0.6672000288963318, 0.6974999904632568] / 0.6869600057601929 )\n",
            "[110] ( [0.6615999937057495, 0.6945000290870667, 0.7003999948501587, 0.689300000667572, 0.685699999332428] / 0.686300003528595 )\n",
            "[111] ( [0.6571000218391418, 0.657800018787384, 0.6675999760627747, 0.6434999704360962, 0.6496000289916992] / 0.6551200032234192 )\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boxes': [<matplotlib.lines.Line2D at 0x7f8934f53090>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8934f53cd0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8932ca2f90>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab54a4310>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ae8470190>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8a2401f150>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab54d0a90>,\n",
              "  <matplotlib.lines.Line2D at 0x7f89344ca5d0>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7f8a3c1c7290>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8a3c1c7090>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab5507c10>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab5507410>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8a241b4450>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8a241b4890>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ad6184150>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ad6184890>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab540fc90>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab540f990>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ae8544350>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ae8544b50>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab54a0dd0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab54c8b90>,\n",
              "  <matplotlib.lines.Line2D at 0x7f893461a9d0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f893461a0d0>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7f8a2403e190>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab53abb10>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab54a4890>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ae8470210>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8a2401d6d0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab54d0cd0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab54c8b10>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ad63cc510>],\n",
              " 'means': [],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7f8a2403e510>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ae8366410>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8a241b4fd0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ad6184dd0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8a2401d550>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab54d0f10>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab54c89d0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ae82c0150>],\n",
              " 'whiskers': [<matplotlib.lines.Line2D at 0x7f8a2420ad50>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8a2420a250>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8934f535d0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8934f53610>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab54dee10>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8a240170d0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab54a4390>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ae8447b50>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ae8470850>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab540f610>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8a2401f950>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8a2401f590>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab54a02d0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f8ab54a0f10>,\n",
              "  <matplotlib.lines.Line2D at 0x7f89344ca2d0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f893461ae90>]}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1125) 해결하기 위해 코드 추가\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "# CIFAR-10 데이터셋을 읽고 신경망에 입력할 형태로 변환\n",
        "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
        "x_train=x_train.astype(np.float32)/255.0\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "# 하이퍼 매개변수 설정\n",
        "batch_siz=128\n",
        "n_epoch=5\n",
        "k=5 # k-folds\n",
        "\n",
        "# 하이퍼 매개변수에 따라 교차 검증을 수행하고 정확률을 반환하는 함수\n",
        "def cross_validation(data_gen,dropout_rate,l2_reg):\n",
        "    accuracy=[]\n",
        "    for train_index,val_index in KFold(k).split(x_train):\n",
        "        xtrain,xval=x_train[train_index],x_train[val_index]\n",
        "        ytrain,yval=y_train[train_index],y_train[val_index]\n",
        "\n",
        "        # 신경망 모델 설계\n",
        "        cnn=Sequential()\n",
        "        cnn.add(Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))\n",
        "        cnn.add(Conv2D(32,(3,3),activation='relu'))\n",
        "        cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "        cnn.add(Dropout(dropout_rate[0]))\n",
        "        cnn.add(Conv2D(64,(3,3),activation='relu'))\n",
        "        cnn.add(Conv2D(64,(3,3),activation='relu'))\n",
        "        cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "        cnn.add(Dropout(dropout_rate[1]))\n",
        "        cnn.add(Flatten())\n",
        "        cnn.add(Dense(512,activation='relu'))\n",
        "        cnn.add(Dropout(dropout_rate[2]))\n",
        "        cnn.add(Dense(10,activation='softmax',kernel_regularizer=regularizers.l2(l2_reg)))\n",
        "\n",
        "        # 신경망을 학습하고 정확률 평가\n",
        "        cnn.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
        "        if data_gen:\n",
        "            generator=ImageDataGenerator(rotation_range=3.0,width_shift_range=0.1,height_shift_range=0.1,horizontal_flip=True)\n",
        "            cnn.fit_generator(generator.flow(x_train,y_train,batch_size=batch_siz),epochs=n_epoch,validation_data=(x_test,y_test),verbose=2)\n",
        "        else:\n",
        "            cnn.fit(xtrain,ytrain,batch_size=batch_siz,epochs=n_epoch, validation_data=(x_test,y_test),verbose=2)\n",
        "        accuracy.append(cnn.evaluate(xval,yval,verbose=0)[1])\n",
        "    return accuracy\n",
        "\n",
        "# 하이퍼 매개변수를 달리 하며 신경망 모델을 평가\n",
        "print('acc_000'); acc_000=cross_validation(False,[0.0,0.0,0.0],0.0)\n",
        "print('acc_001'); acc_001=cross_validation(False,[0.0,0.0,0.0],0.01)\n",
        "print('acc_010'); acc_010=cross_validation(False,[0.25,0.25,0.5],0.0)\n",
        "print('acc_011'); acc_011=cross_validation(False,[0.25,0.25,0.5],0.01)\n",
        "print('acc_100'); acc_100=cross_validation(True,[0.0,0.0,0.0],0.0)\n",
        "print('acc_101'); acc_101=cross_validation(True,[0.0,0.0,0.0],0.01)\n",
        "print('acc_110'); acc_110=cross_validation(True,[0.25,0.25,0.5],0.0)\n",
        "print('acc_111'); acc_111=cross_validation(True,[0.25,0.25,0.5],0.01)\n",
        "\n",
        "print(\"출력 형식: [Data augmentation-Dropout-l2 regularizer] (교차검증 시도/평균)\")\n",
        "print(\"[000] (\",acc_000,\"/\",np.array(acc_000).mean(),\")\")\n",
        "print(\"[001] (\",acc_001,\"/\",np.array(acc_001).mean(),\")\")\n",
        "print(\"[010] (\",acc_010,\"/\",np.array(acc_010).mean(),\")\")\n",
        "print(\"[011] (\",acc_011,\"/\",np.array(acc_011).mean(),\")\")\n",
        "print(\"[100] (\",acc_100,\"/\",np.array(acc_100).mean(),\")\")\n",
        "print(\"[101] (\",acc_101,\"/\",np.array(acc_101).mean(),\")\")\n",
        "print(\"[110] (\",acc_110,\"/\",np.array(acc_110).mean(),\")\")\n",
        "print(\"[111] (\",acc_111,\"/\",np.array(acc_111).mean(),\")\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 박스 플롯으로 정확률 표시\n",
        "plt.grid()\n",
        "plt.boxplot([acc_000,acc_001,acc_010,acc_011,acc_100,acc_101,acc_110,acc_111],labels=[\"000\",\"001\",\"010\",\"011\",\"100\",\"101\",\"110\",\"111\"])\n",
        "# plt.boxplot([acc_000,acc_001],labels=[\"000\",\"001\"])"
      ]
    }
  ]
}