{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "tf.keras_DNN_BMI.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjyjung/ai/blob/gh-pages/tf_keras_DNN_BMI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22UZuhWkLtVt"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers  #모듈(변수나 함수를 포함)만 불러오기\n",
        "\n",
        "# BMI 데이터를 읽어 들이고 정규화하기\n",
        "csv = pd.read_csv(\"bmi.csv\")\n",
        "\n",
        "# 몸무게와 키 데이터\n",
        "csv[\"weight\"] /= 100   #normalization\n",
        "csv[\"height\"] /= 200   #normalization\n",
        "X = csv[[\"weight\", \"height\"]].as_matrix()\n",
        "X = csv.iloc[:,0:2]\n",
        "\n",
        "# 레이블\n",
        "bclass = {\"thin\":[1,0,0], \"normal\":[0,1,0], \"fat\":[0,0,1]}\n",
        "y = np.empty((20000,3))     # 2000x3 크기의 다차원 벡터 생성\n",
        "for i, v in enumerate(csv[\"label\"]):\n",
        "    y[i] = bclass[v]        #\"thin'이면, y[i]=[1,0,0] 와 같이 할당\n",
        "    \n",
        "# 훈련 전용 데이터와 테스트 전용 데이터로 나누기\n",
        "X_train, y_train = X[0:15000], y[0:15000]\n",
        "X_test,  y_test  = X[15000:20000], y[15000:20000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "G2UgYhccLtVu",
        "outputId": "0f6d18bf-32cd-4b23-f425-a3abbf926c61"
      },
      "source": [
        "# 모델 구조 정의하기\n",
        "model = tf.keras.Sequential()  #순차적 계층화 준비\n",
        "model.add(layers.Dense(8, input_shape=(2,)))  #입력 2개로부터 전달받는 8개 노드의 layer 생성\n",
        "model.add(layers.Activation('relu'))  #ReLU 활성화함수 채택\n",
        "model.add(layers.Dropout(0.1))        #dropout ratio=10% (배치 훈련시 10% arc 무시)\n",
        "\n",
        "model.add(layers.Dense(4))         #4개 노드의 layer 생성\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Dropout(0.1))\n",
        "\n",
        "model.add(layers.Dense(3))\n",
        "model.add(layers.Activation('softmax')) #분류(classification)을 위해 softmax 함수 사용\n",
        "\n",
        "# 모델 구축하기\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',  #다중 교차엔트로피\n",
        "    optimizer=\"rmsprop\",   #최적화 기법 중 하나\n",
        "    metrics=['accuracy'])  #정확도 측정"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\jyjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From C:\\Users\\jyjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2IhHchdXLtVv",
        "outputId": "7f77c92e-e3e4-4e08-dc84-08bd6e0e9ae3"
      },
      "source": [
        "# 데이터 훈련하기\n",
        "hist = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=100,  #100개에 한 번씩 업데이터 실행\n",
        "    epochs=50,       #훈련 데이터셋을 총 20회 반복 실험. 단, 조기중지될 수 있음\n",
        "    validation_split=0.2,  \n",
        "      #validation data 분할 비율. 즉, 15000개 중에서 10%인 1500개를 validation용으로 분할\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)],  \n",
        "      #'val_loss'를 monitor하여 감소하면 한 번 더(1) 참고 조기중지\n",
        "    verbose=1)  #전 과정을 화면에 출력(1) 또는 미출력(0) 모드\n",
        "\n",
        "# 테스트 데이터로 평가하기\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print('test_loss: ', score[0])\n",
        "print('test_acc: ', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 12000 samples, validate on 3000 samples\n",
            "WARNING:tensorflow:From C:\\Users\\jyjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/50\n",
            "12000/12000 [==============================] - 0s 29us/sample - loss: 2.6509 - acc: 0.3069 - val_loss: 1.1011 - val_acc: 0.3237\n",
            "Epoch 2/50\n",
            "12000/12000 [==============================] - 0s 12us/sample - loss: 1.8506 - acc: 0.4616 - val_loss: 0.9341 - val_acc: 0.4837\n",
            "Epoch 3/50\n",
            "12000/12000 [==============================] - 0s 12us/sample - loss: 1.7379 - acc: 0.4695 - val_loss: 0.8949 - val_acc: 0.4897\n",
            "Epoch 4/50\n",
            "12000/12000 [==============================] - 0s 12us/sample - loss: 1.7607 - acc: 0.4678 - val_loss: 0.8671 - val_acc: 0.5030\n",
            "Epoch 5/50\n",
            "12000/12000 [==============================] - 0s 12us/sample - loss: 1.7244 - acc: 0.4929 - val_loss: 0.8300 - val_acc: 0.6293\n",
            "Epoch 6/50\n",
            "12000/12000 [==============================] - 0s 12us/sample - loss: 1.5035 - acc: 0.5615 - val_loss: 0.8162 - val_acc: 0.6233\n",
            "Epoch 7/50\n",
            "12000/12000 [==============================] - 0s 12us/sample - loss: 1.3265 - acc: 0.5658 - val_loss: 0.7947 - val_acc: 0.6270\n",
            "Epoch 8/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.3024 - acc: 0.5943 - val_loss: 0.7701 - val_acc: 0.6747\n",
            "Epoch 9/50\n",
            "12000/12000 [==============================] - 0s 12us/sample - loss: 1.2492 - acc: 0.6122 - val_loss: 0.7403 - val_acc: 0.7040\n",
            "Epoch 10/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.2595 - acc: 0.6205 - val_loss: 0.7165 - val_acc: 0.7090\n",
            "Epoch 11/50\n",
            "12000/12000 [==============================] - 0s 12us/sample - loss: 1.2436 - acc: 0.6161 - val_loss: 0.6996 - val_acc: 0.7147\n",
            "Epoch 12/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.1835 - acc: 0.6166 - val_loss: 0.6808 - val_acc: 0.7177\n",
            "Epoch 13/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.2042 - acc: 0.6195 - val_loss: 0.6683 - val_acc: 0.7230\n",
            "Epoch 14/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.1965 - acc: 0.6194 - val_loss: 0.6516 - val_acc: 0.7180\n",
            "Epoch 15/50\n",
            "12000/12000 [==============================] - 0s 12us/sample - loss: 1.2228 - acc: 0.6200 - val_loss: 0.6513 - val_acc: 0.7247\n",
            "Epoch 16/50\n",
            "12000/12000 [==============================] - 0s 12us/sample - loss: 1.2233 - acc: 0.6202 - val_loss: 0.6465 - val_acc: 0.7247\n",
            "Epoch 17/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.1539 - acc: 0.6227 - val_loss: 0.6278 - val_acc: 0.7183\n",
            "Epoch 18/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.1694 - acc: 0.6324 - val_loss: 0.6239 - val_acc: 0.7330\n",
            "Epoch 19/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.1895 - acc: 0.6309 - val_loss: 0.6126 - val_acc: 0.7260\n",
            "Epoch 20/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.1738 - acc: 0.6480 - val_loss: 0.5663 - val_acc: 0.7450\n",
            "Epoch 21/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.1268 - acc: 0.6564 - val_loss: 0.5417 - val_acc: 0.7630\n",
            "Epoch 22/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.0732 - acc: 0.6634 - val_loss: 0.5388 - val_acc: 0.7417\n",
            "Epoch 23/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.1257 - acc: 0.6622 - val_loss: 0.5328 - val_acc: 0.7453\n",
            "Epoch 24/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.1086 - acc: 0.6608 - val_loss: 0.5094 - val_acc: 0.7743\n",
            "Epoch 25/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.0928 - acc: 0.6677 - val_loss: 0.5058 - val_acc: 0.7747\n",
            "Epoch 26/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.0654 - acc: 0.6697 - val_loss: 0.5081 - val_acc: 0.7513\n",
            "Epoch 27/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.0904 - acc: 0.6662 - val_loss: 0.4630 - val_acc: 0.7963\n",
            "Epoch 28/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.0440 - acc: 0.6746 - val_loss: 0.4567 - val_acc: 0.7900\n",
            "Epoch 29/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.0654 - acc: 0.6692 - val_loss: 0.4900 - val_acc: 0.7680\n",
            "Epoch 30/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.0594 - acc: 0.6793 - val_loss: 0.4426 - val_acc: 0.7970\n",
            "Epoch 31/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.0334 - acc: 0.6794 - val_loss: 0.4625 - val_acc: 0.7867\n",
            "Epoch 32/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 0.9898 - acc: 0.6883 - val_loss: 0.4605 - val_acc: 0.7880\n",
            "Epoch 33/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.0352 - acc: 0.6923 - val_loss: 0.4552 - val_acc: 0.7853\n",
            "Epoch 34/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.0585 - acc: 0.6864 - val_loss: 0.4399 - val_acc: 0.8087\n",
            "Epoch 35/50\n",
            "12000/12000 [==============================] - 0s 12us/sample - loss: 1.0558 - acc: 0.6911 - val_loss: 0.4114 - val_acc: 0.8160\n",
            "Epoch 36/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.0424 - acc: 0.6894 - val_loss: 0.4123 - val_acc: 0.8163\n",
            "Epoch 37/50\n",
            "12000/12000 [==============================] - 0s 9us/sample - loss: 1.0058 - acc: 0.6944 - val_loss: 0.4384 - val_acc: 0.8047\n",
            "Epoch 38/50\n",
            "12000/12000 [==============================] - 0s 9us/sample - loss: 1.0005 - acc: 0.6994 - val_loss: 0.4039 - val_acc: 0.8170\n",
            "Epoch 39/50\n",
            "12000/12000 [==============================] - 0s 9us/sample - loss: 1.0420 - acc: 0.6968 - val_loss: 0.4031 - val_acc: 0.8500\n",
            "Epoch 40/50\n",
            "12000/12000 [==============================] - 0s 9us/sample - loss: 1.0131 - acc: 0.6999 - val_loss: 0.3952 - val_acc: 0.8393\n",
            "Epoch 41/50\n",
            "12000/12000 [==============================] - 0s 9us/sample - loss: 0.9929 - acc: 0.7035 - val_loss: 0.4212 - val_acc: 0.8167\n",
            "Epoch 42/50\n",
            "12000/12000 [==============================] - 0s 9us/sample - loss: 1.0014 - acc: 0.7074 - val_loss: 0.4386 - val_acc: 0.8067\n",
            "Epoch 43/50\n",
            "12000/12000 [==============================] - 0s 9us/sample - loss: 0.9938 - acc: 0.7041 - val_loss: 0.3809 - val_acc: 0.8403\n",
            "Epoch 44/50\n",
            "12000/12000 [==============================] - 0s 9us/sample - loss: 1.0141 - acc: 0.7088 - val_loss: 0.3739 - val_acc: 0.8420\n",
            "Epoch 45/50\n",
            "12000/12000 [==============================] - 0s 10us/sample - loss: 1.0149 - acc: 0.7113 - val_loss: 0.4196 - val_acc: 0.8203\n",
            "Epoch 46/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 0.9942 - acc: 0.7030 - val_loss: 0.3654 - val_acc: 0.8497\n",
            "Epoch 47/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 0.9844 - acc: 0.7114 - val_loss: 0.3580 - val_acc: 0.8750\n",
            "Epoch 48/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 1.0069 - acc: 0.7066 - val_loss: 0.3532 - val_acc: 0.8723\n",
            "Epoch 49/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 0.9794 - acc: 0.7122 - val_loss: 0.3914 - val_acc: 0.8307\n",
            "Epoch 50/50\n",
            "12000/12000 [==============================] - 0s 11us/sample - loss: 0.9938 - acc: 0.7101 - val_loss: 0.3527 - val_acc: 0.8537\n",
            "5000/5000 [==============================] - 0s 14us/sample - loss: 0.3524 - acc: 0.8522\n",
            "test_loss:  0.35243621215820314\n",
            "test_acc:  0.8522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Hh1NwcAwLtVw",
        "outputId": "4bf5845d-13db-4ef2-ea0d-5a4e44a790b5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0LNN770LtVw",
        "outputId": "cc45bde1-2c8b-4424-b748-056ada18292f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 8)                 24        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 36        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 15        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 75\n",
            "Trainable params: 75\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "nhPK4V6nLtVx",
        "outputId": "c7039c5c-e7d5-40a4-abb8-81dfe65f1cc5"
      },
      "source": [
        "model.save(\"dnn_BMI.h5\")\n",
        "print(\"Saved model to disk.\")\n",
        "\n",
        "#load and evaluate the saved model\n",
        "from numpy import loadtxt\n",
        "from tensorflow.python.keras.models import load_model\n",
        "\n",
        "#load model\n",
        "loaded_model = load_model(\"dnn_BMI.h5\")\n",
        "model.summary()\n",
        "\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print('test_loss: ', score[0])\n",
        "print('test_acc: ', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model to disk.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 8)                 24        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 36        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 15        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 75\n",
            "Trainable params: 75\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "5000/5000 [==============================] - 0s 16us/sample - loss: 0.3524 - acc: 0.8522\n",
            "test_loss:  0.35243621215820314\n",
            "test_acc:  0.8522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "w2qbzPOtLtVx",
        "outputId": "6e226dca-598b-4478-ca54-e7da435d3dca"
      },
      "source": [
        "model.save(\"dnn_bmi.h5\")\n",
        "print(\"Saved model to disk.\")\n",
        "\n",
        "#load and evaluate the saved model\n",
        "from numpy import loadtxt\n",
        "from tensorflow.python.keras.models import load_model\n",
        "\n",
        "#load model\n",
        "loaded_model = load_model(\"dnn_bmi.h5\")\n",
        "model.summary()\n",
        "\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print('test_loss: ', score[0])\n",
        "print('test_acc: ', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model to disk.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 8)                 24        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 36        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 15        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 75\n",
            "Trainable params: 75\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "5000/5000 [==============================] - 0s 15us/sample - loss: 0.3524 - acc: 0.8522\n",
            "test_loss:  0.35243621215820314\n",
            "test_acc:  0.8522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8sQr21XLtVy",
        "outputId": "7f90013d-f483-496d-c526-394adf636083"
      },
      "source": [
        "#X_test의 예측 클래스 확인하기\n",
        "y_pred = model.predict_classes(X_test)\n",
        "y_pred[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 0, 1, 0, 1, 1, 2, 0, 2, 1], dtype=int64)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "X0AuQV5wLtVy",
        "outputId": "c9d16bf2-4013-46e1-87b9-b3ca6d19f6d0"
      },
      "source": [
        "#X_test의 클래스별 예측 확률 확인하기\n",
        "y_pred_prob = model.predict_proba(X_test)\n",
        "y_pred_prob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2.4848736e-05, 4.0614423e-01, 5.9383088e-01],\n",
              "       [9.0394133e-01, 9.6058697e-02, 5.7913604e-28],\n",
              "       [1.5519175e-04, 7.5911045e-01, 2.4073437e-01],\n",
              "       ...,\n",
              "       [9.8674959e-01, 1.3250425e-02, 0.0000000e+00],\n",
              "       [8.9777589e-01, 1.0222407e-01, 4.8346007e-27],\n",
              "       [1.3000222e-06, 4.7824937e-01, 5.2174932e-01]], dtype=float32)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuwpHQXlLtVy",
        "outputId": "0de76128-a968-449e-c66d-604770530936"
      },
      "source": [
        "y_pred = model.predict_classes(X_test[0:5])\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 0, 1, 0, 1], dtype=int64)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sQBMOezLtVz",
        "outputId": "a612d40e-d55b-4387-fc2b-f2f9f5021d28"
      },
      "source": [
        "X_test[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15000</th>\n",
              "      <td>138</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15001</th>\n",
              "      <td>152</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15002</th>\n",
              "      <td>183</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15003</th>\n",
              "      <td>198</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15004</th>\n",
              "      <td>149</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       height  weight\n",
              "15000     138      55\n",
              "15001     152      36\n",
              "15002     183      72\n",
              "15003     198      51\n",
              "15004     149      47"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVYBzLvnLtVz",
        "outputId": "62c22380-ed26-4874-fb12-e6285c6b8a20"
      },
      "source": [
        "y_pred = model.predict_classes(X_test[[1]])\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"None of [Int64Index([1], dtype='int64')] are in the [columns]\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-12-f417f88a61f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[1;32m-> 2934\u001b[1;33m                                                    raise_missing=True)\n\u001b[0m\u001b[0;32m   2935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[0;32m   1353\u001b[0m                           raise_missing}\n\u001b[1;32m-> 1354\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1355\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[0;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1244\u001b[0m                 raise KeyError(\n\u001b[0;32m   1245\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[1;32m-> 1246\u001b[1;33m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([1], dtype='int64')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDjOYxUzLtVz"
      },
      "source": [
        "X_test[[1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOdX9FRmLtVz"
      },
      "source": [
        "X_test[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34Xez1yYLtV0"
      },
      "source": [
        "X_new = [80, 175]\n",
        "X_new[0]/=100\n",
        "X_new[1]/=200\n",
        "X_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "JT9wDV5NLtV0"
      },
      "source": [
        "y_pred = model.predict_classes(np.array([X_new,]))\n",
        "y_pred_prob = model.predict_proba(np.array([X_new,]))\n",
        "print(y_pred, y_pred_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flB-FoC2LtV0"
      },
      "source": [
        "def predict_bmi(X_new):\n",
        "    y_pred = model.predict_classes(np.array([X_new,]))\n",
        "    y_pred_prob = model.predict_proba(np.array([X_new,]))\n",
        "    print(y_pred, y_pred_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMJdeu5nLtV0"
      },
      "source": [
        "X_mean = [X_train[:,0].mean(), X_train[:,1].mean()] #normal (1)\n",
        "X_min = [X_train[:,0].min(), X_train[:,1].min()] #normal (1)\n",
        "X_max = [X_train[:,0].max(), X_train[:,1].max()] #normal (1)\n",
        "X_min_max = [X_train[:,0].min(), X_train[:,1].max()]  #thin (0)\n",
        "X_max_min = [X_train[:,0].max(), X_train[:,1].min()]  #fat (2)\n",
        "print(\"X_mean : \", X_mean)\n",
        "print(\"X_min : \", X_min)\n",
        "print(\"X_max : \", X_max)\n",
        "print(\"X_min_max : \", X_min_max)\n",
        "print(\"X_max_min : \", X_max_min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWhXRZUYLtV1"
      },
      "source": [
        "predict_bmi(X_mean)\n",
        "predict_bmi(X_min)\n",
        "predict_bmi(X_max)\n",
        "predict_bmi(X_min_max)\n",
        "predict_bmi(X_max_min)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}